knit("PA1_template.Rmd")
install.packages(c("car", "dendextend", "googleVis", "NLP", "RCurl", "rjson", "RJSONIO", "xlsx"))
require('dev')
#Only the first time data is download, a "data" directory is created.
if (!file.exists("data")) {
dir.create("data")
}
#and stores that file into "data" directory
if(!file.exists("data/repdata-data-StormData.csv.bz2")) {
fileURL <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileURL, destfile = "./data/repdata-data-StormData.csv.bz2")
}
#Uncompress and reads if not exists. Stores data in storm.noaa.data variable.
if(!file.exists("data/storm_noaa_data.dat")){
storm.noaa.data <- read.csv(bzfile("./data/repdata-data-StormData.csv.bz2"))
write.table(storm.noaa.data, "data/storm_noaa_data.dat")
}else{
storm.noaa.data <- read.table("data/storm_noaa_data.dat")
}
#subsets those requested columns and stores in work.data variable.
work.data <- subset(storm.noaa.data, FATALITIES > 0 | INJURIES > 0 | PROPDMG > 0 | CROPDMG > 0, select = c(8, 23:28))
#transforms exponents into numeric values hecto=100, kilo=1000, million=1000000=1e+06 etc..
expcalc <- function(dam,exp) {
if (exp == "") {
dam * 1
} else if (exp == "1") {
dam * 10
} else if (exp == "H" | exp == "h") {
dam * 100
} else if (exp == "K" | exp == "k") {
dam * 1000
} else if (exp == "M" | exp == "m") {
dam * 1e+06
} else if (exp == "B" | exp == "b") {
dam * 1e+09
} else 0
}
#creates two new columns,applying those exponents to property damage(PDCOST), and crop damage(CROPCOST)
work.data$PDCOST <- mapply(expcalc, work.data$PROPDMG, work.data$PROPDMGEXP)
work.data$CROPCOST <- mapply(expcalc, work.data$CROPDMG, work.data$CROPDMGEXP)
##trying to get tidier data, transform EVTYPE column to lower case. Makes it as factor again.
work.data$EVTYPE <- tolower(work.data$EVTYPE)
work.data$EVTYPE <- as.factor(work.data$EVTYPE)
require(ggplot2)
require(reshape2)
# melt function needs reshape2 package
#melt function: id.vars is a vector of id variables. measure.vars is a vector of measured variables
#In pop.health stores 3 columns: "EVTYPE"   "variable" "value"
pop.health <- melt(work.data[,c(1:3)], id.vars = "EVTYPE", measure.vars= c("FATALITIES", "INJURIES"))
#In pop.health.agg stores 3 columns: "EVTYPE"        "Casualty" "Count"
#there are 488 events, but 2 types: fatalities and injuries, so 976 rows
pop.health.agg <- setNames(aggregate(value ~ EVTYPE+variable, data=pop.health, sum, na.rm = TRUE), c("EVTYPE","Casualty","Count"))
#In total stores each 447 type of events and the sum/Count each one
total <- aggregate(Count ~ EVTYPE, pop.health.agg, sum)
#In pop.health.agg2 stores "EVTYPE" "Casualty" "Count.x" "Count.y"
pop.health.agg2 <- merge(pop.health.agg, total, by = "EVTYPE")
#orders and select first 20
pop.health.agg2 <- pop.health.agg2[order(-pop.health.agg2$Count.y, pop.health.agg2$Casualty), ][1:20, ]
#Prepares by factoring to plot
pop.health.agg2$EVTYPE <-suppressWarnings(factor(pop.health.agg2$EVTYPE, levels=pop.health.agg2[order(pop.health.agg2$Count.y), "EVTYPE"]))
ggplot(pop.health.agg2, aes(x = EVTYPE, y = Count.x, fill = Casualty)) + geom_bar(stat = "identity") + coord_flip() +
ylab("Fatality Injury") +
xlab("Type of Event") +
ggtitle("Fatalities and Injuries by Type of Event")
storm <- read.csv("storm_data.csv.bz2")
str(storm)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('caret')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
require('shiny')
install.packages(c("bdsmatrix", "BH", "ChainLadder", "DBI", "FactoMineR", "formatR", "gsubfn", "httr", "labeling", "markdown", "NLP", "packrat", "RCurl", "rjson", "RJSONIO", "sandwich", "spacetime", "swirl", "xlsx", "xlsxjars"))
install.packages(c("bdsmatrix", "ChainLadder", "DBI", "FactoMineR", "formatR", "gsubfn", "httr", "labeling", "markdown", "NLP", "packrat", "RCurl", "rjson", "RJSONIO", "sandwich", "spacetime", "swirl", "xlsx", "xlsxjars"))
install.packages(c("bdsmatrix", "RCurl", "rjson", "RJSONIO", "xlsx", "xlsxjars"))
install.packages('bdsmatrix')
install.packages("bdsmatrix")
install.packages("bdsmatrix")
install.packages("bdsmatrix")
install.packages(c("bdsmatrix", "RCurl", "rjson", "RJSONIO", "xlsx", "xlsxjars"))
require('shiny')
require('kntri')
require('knitr')
getwd()
mydir <- paste0('getwd(),C:/Users/Scibrokes Trading/Documents/GitHub/englianhu/RepData_PeerAssessment2')
setwd <- mydir
library(knitr)
library(markdown)
# knitr configuration
opts_knit$set(progress=FALSE)
opts_chunk$set(echo=TRUE, message=FALSE, tidy=TRUE, comment=NA,
fig.path="figure/", fig.keep="high", fig.width=10, fig.height=6,
fig.align="center")
knit2html('stormDataAnalysis.Rmd')
browseURL('stormDataAnalysis.html')
mydir <- paste0('getwd(),C:/Users/Scibrokes Trading/Documents/GitHub/englianhu/RepData_PeerAssessment1')
setwd <- mydir
library(knitr)
library(markdown)
# knitr configuration
opts_knit$set(progress=FALSE)
opts_chunk$set(echo=TRUE, message=FALSE, tidy=TRUE, comment=NA,
fig.path="figure/", fig.keep="high", fig.width=10, fig.height=6,
fig.align="center")
knit2html('PA1_template.Rmd')
browseURL('PA1_template.html')
mydir
mydir <- paste0(getwd(),'C:/Users/Scibrokes Trading/Documents/GitHub/englianhu/RepData_PeerAssessment1')
setwd <- mydir
library(knitr)
library(markdown)
# knitr configuration
opts_knit$set(progress=FALSE)
opts_chunk$set(echo=TRUE, message=FALSE, tidy=TRUE, comment=NA,
fig.path="figure/", fig.keep="high", fig.width=10, fig.height=6,
fig.align="center")
knit2html('PA1_template.Rmd')
browseURL('PA1_template.html')
mydir
install.packages("rpubchem")
require('rpubchem')
require(markdown)
library(knitr)
library(markdown)
library(Hmisc)
library(reshape)
library(ggplot2)
library(car)
library(knitr)
library(markdown)
library(formatR)
library(Hmisc)
library(reshape)
library(ggplot2)
library(car)
# knitr configuration
opts_knit$set(progress=FALSE)
opts_chunk$set(echo=TRUE, message=FALSE, tidy=TRUE, comment=NA,
fig.path="figure/", fig.keep="high", fig.width=10, fig.height=6,
fig.align="center")
rpubsUpload(title, htmlFile, id = NULL, properties = list(),
method = getOption("rpubs.upload.method", "internal"))
knit2html('stormDataAnalysis.Rmd')
browseURL('stormDataAnalysis.html')
rpubsUpload(title, htmlFile, id = NULL, properties = list(),
method = getOption("rpubs.upload.method", "internal"))
ToothGrowth
require('swirl')
swirl()
install_from_swirl('Regression Models')
swirl()
plot(child~parent, galton)
plot(jitter(child,4)~parent,galton)
regline <- lm(child~parent,galton)
regrline <- lm(child~parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
lm(child~parent,galton)
fit <- lm(child~parent,galton)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals, galton$parent)
fit$coef[1]
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
lhs==rhs
all.equal(lhs,rhs)
ols(lhs~rhs)
ls(lhs~rhs)
as.environment(pos)
var(lhs)
varChile <- var(galton$child)
varChild <- var(galton$child)
fit$residuals
varRes <- var(fit$residuals)
est(ols.slope~ols.ic)
varEst <- est(ols.slope~ols.ic)
varEst <- est(y~ols.slope+ols.ic)
varEst <- est(ols.slope~ols.ic+1)
varEst <- est(ols.slope~ols.ic+0)
args(est)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, sum(varRes,varEst))
all.equal(varChild, varRes+varEst)
efit <- lm(accel~mag+dist,attenu)
mean(efit$residuals)
cov(efit)
cov(predict(efit))
efit
cov(efit$residuals,attenu$mag)
cov(efit$residuals,attenu$dist)
cor(efits)
efits
args(cor)
cor(gpa_nor,gch_nor)
args(lm)
l_nor <- lm(gch_nor ~ gpa_nor)
args(lm)
fit <- lm(child~parent, galton)
sqrt(n-2)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
args(expr)
args(expression)
mu <- mean(galton$child)
args(sqrt)
sTot <- sum((galton$child-mu)^2)
args(res)
args(residuals)
sRes <- deviance(fit)
sRes/sTot
1-sRes/sTot
summary(fit)$r
summary(fit)$r.squared
args(core)
args(cor)
cor(galton$parent, galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child~1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant-1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
args(lm)
all <- lm(Fertility~., swiss)
summary(all)
summary(all)
summary(lm(Fertility~Agriculture, swiss))
args(cor)
cor(swiss$Examination, swiss$Education)
swiss[1:2,]
cor(swiss$Agriculture, swiss$Education)
makelms()
swiss$Catholic
ec <- swiss$Examination+swiss$Catholic
args(efit)
efit <- lm(Fertility~. + ex, swiss)
efit <- lm(Fertility~. + ec, swiss)
efit$coef
all$coefficients-efit$coefficients
Multivar_Examples2
dataset(Multivar_Examples2)
datasets(Multivar_Examples2)
args(Insect)
InsectSprays
nrow(InsectSprays)
swirl()
nrow(InsectSprays)
names(InsectSprays)
levels(InsectSprays$spray)
length(levels(InsectSprays$spray))
str(InsectSprays)
string(InsectSprays)
dim(InsectSprays)
InsectSprays[15,]
head(InsectSprays,15)
arr
array
SB
InsectSprays
args(array)
info()
S8
SB
sB
M[,2]
args(array)
summary(InsectSprays[,2])
args(sapply)
sapply(InsectSprays,class)
args(lm)
fit <- lm(count~spray, InsectSprays)
x$coef
fit$coef
summary(fit)$coef
args(array)
est <- summary(fit)$coef[,1]
args(groups)
args(dummy)
InsectSprays
mean(SA)
mean(sA)
mean(sprayB)
sprayB
args(mean)
mean(sB)
args(lm)
nfit <- lm(count~spray-1,InsectSprays)
summary(nfit)
summary(nfit)$coef
InsectSprays$spray
spray2 <- relevel(InsectSprays$spray,\"C\")
spray2 <- relevel(InsectSprays$spray,'C')
fit2 <- lm(InsectSprays)
fit2 <- lm(count~spray2,InsectSprays)
args(fit2)
summary(fit2)$coef
args(array)
mean(sC)
args(fit$coef[2])
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
names(hunger)
dim(hunger)
swirl()
nrow(hunger)
names(hunger)
args(lm)
fit <- lm(hunger$Numeric ~ hunger$Year)
summary(fit)
summary(fit)$coef
args(lmF)
[hunger$Sex=="Female"]
args(lm)
lmF <- lm(Numeric[Sex=="Female"] ~ Year[Sex=="Female"],hunger)
lmM
args(lm)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
args(lmBoth)
args(lm)
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex)
args(lm)
summary(lmBoth)
args(lm)
lmInter <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex + hunger$Year * hunger$Sex)
summary(lmInter)
fit <- lm(y ~ x, out2)
lm$residuals
summary(lm)$residuals
summary(fit)
summary(fit)$residuals
plot(fit, which=1)
out2[-1, ]
fitno <- lm(y ~ x, out2[-1, ])
plot(residuals~fitted, fitno)
plot(lm(residuals~fitted, fitno))
plot(lm(fitno$residuals~fitno$fitted, fitno))
args(lm)
plot(fitno, which=1)
coef(fit)
coef(fit)-coef(fitno)
dfbeta(fit)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
args(lm)
sigma <- sqrt(deviance(fit)/df.residual(fit))
sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
args(lm)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
predict(fit, out2)
dy <- predict(fitno, out2)-predict(fit, out2)
2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
args(lm)
rpg1()
rgp1()
rgp2()
head(swiss)
args(lm)
mdl <- lm(Fertility ~ ., swiss)
vif(mdl)
mdl2
args(lm)
mdl2 <- lm(Fertility ~ . -Examination, swiss)
vif(mdl2)
args(lm)
x1c <- simbias()
apply(x1c, 1, mean)
args(lm)
fit1 <- lm(Fertility ~ Agriculture, swiss)
args(lm)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
args(lm)
anova(fit1, fit3)
args(lm)
deviance(fit3)
args(lm)
d <- deviance(fit3)/43
args(lm)
n <- (deviance(fit1) - deviance(fit3))/2
args(lm)
n/d
args(lm)
pf(n/d, 2, 43, lower.tail=FALSE)
args(lm)
shapiro.test(fit3$residuals)
args(lm)
anova(fit1, fit3, fit5, fit6)
args(lm)
View(ravenData)
args(lm)
mdl <- glm(ravenWinNum ~ ravenScore, binomial, ravenData)
args(lm)
lodds <- predict(mdl, data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
args(lm)
exp(confint(mdl))
anova(mdl)
args(lm)
qchisq(0.95, 1)
args(lm)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(b1)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits']
)
hits[704,]
mdl$fitted.values[704]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
args(glm)
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
require('swirl')
require('caret')
library(kernlab)
install.packages(kernlab)
## Read the dataset
train <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', header=T, sep=',', na.strings='?')
require('ggplot2')
if(!file.exists('./data')){dir.create('./data')}
fileUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
destfile <- 'train.csv'
download.file(fileUrl, destfile=paste('data', destfile, sep='/'))
## Read the dataset
train <- read.csv('./data/train.csv', header=T, sep=',', na.strings='?')
train
if(!file.exists('./data')){dir.create('./data')}
fileUrl <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
destfile <- 'test.csv'
download.file(fileUrl, destfile=paste('data', destfile, sep='/'))
## Read the dataset
train <- read.csv('./data/test.csv', header=T, sep=',', na.strings='?')
answers = rep("A", 20)
rm(train)
rm(destfile,fileurl)
rm(fileUrl)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
require('UsingR')
install.packages('UsingR')
require('shiny')
require('usingR')
require('UsingR')
require('rChart')
install.packages('rChart')
library(manipulate)
require(shiny)
runApp()
require('rms')
install.packages('rms')
install.packages('mgcv')
require('rms')
require('lm')
require('lme')
install.packages('lme')
install.packages(c("htmltools", "jsonlite", "R2HTML", "raster", "Rcmdr", "RcmdrMisc", "rgl"))
mydir <- paste0(getwd(),'/GitHub/englianhu/Statistical_Inference')
setwd(mydir)
library(datasets)
library(knitr)
library(markdown)
library(formatR)
library(Hmisc)
library(reshape)
library(ggplot2)
library(car)
# knitr configuration
opts_knit$set(progress=FALSE)
opts_chunk$set(echo=TRUE, message=FALSE, tidy=TRUE, comment=NA,
fig.path="figure/", fig.keep="high", fig.width=10, fig.height=6,
fig.align="center")
knit2html('StatsInf_Assignment.Rmd')
browseURL('StatsInf_Assignment.html')
# rpubsUpload(title, htmlFile, id = NULL, properties = list(),
#             method = getOption("rpubs.upload.method", "internal"))
